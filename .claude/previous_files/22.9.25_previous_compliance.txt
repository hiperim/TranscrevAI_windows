# TRANSCREVAI PROJECT COMPLIANCE RULES
*Enhanced for systematic validation and error prevention*

**MANDATORY ADHERENCE**: All TranscrevAI development must comply with these rules. Violations will cause system instability and performance degradation.

---

## CORE PERFORMANCE REQUIREMENTS

### Rule 1: Audio Processing Performance Standards
- **Processing Speed**: Achieve ~0.5s processing time per 1s of recorded audio, with stability
- **Accuracy Target**: Maintain â‰¥95% accuracy in both transcription and diarization
- **Language Optimization**: PT-BR (Portuguese Brazilian) exclusive optimization
- **Model Restriction**: Use ONLY "medium" model for all operations
- **Conversation Focus**: Optimize specifically for conversational audio patterns

**VALIDATION**: Test all implementations against processing speed and accuracy targets before deployment. On folder "data/recordings", For transcription and diarization, compare audio files with expected benchmarks ("benchmark_'filename'.txt" with "filename.wav" - example:  audio file "t.speakers.wav" and expected results for transcription and diarization "benchmark_t.speakers.txt")


### Rule 2: Speaker Diarization Constraints
- **Dynamic Speaker Detection**: NEVER presume fixed number of speakers
- **Adaptive Processing**: Handle variable speaker counts per audio file
- **Real-World Optimization**: Optimize for actual usage patterns, not theoretical scenarios

**VALIDATION**: On folder "data/recordings", For transcription and diarization, compare audio files with expected benchmarks ("benchmark_'filename'.txt" with "filename.wav" - example:  audio file "q.speakers.wav" and expected results for transcription and diarization "benchmark_q.speakers.txt")

### Rule 3: System Stability Requirements
- **Historical Context**: Previous over-implementation caused system crashes and instability
- **Incremental Approach**: Implement features gradually with testing at each step
- **Performance Maintenance**: Never sacrifice core performance metrics for additional features
- **Rollback Capability**: Maintain ability to revert changes that degrade performance

**VALIDATION**: After each implementation, verify system stability and performance metrics.

---

## RESOURCE OPTIMIZATION REQUIREMENTS

### Rule 4-5: Memory Management
- **RAM Limit**: Maintain ~2GB RAM usage for single PT-BR model operations
- **Memory Efficiency**: Optimize all code for minimal memory footprint
- **Model Loading**: Load only required PT-BR medium model, no multi-model support

**VALIDATION**: Monitor memory usage during processing and optimize if >2GB.

### Rule 6-8: Language and Model Optimization
- **Exclusive PT-BR Focus**: All improvements and corrections for Portuguese Brazilian only
- **Single Model Strategy**: Use exclusively "medium" model for Portuguese Brazilian
- **No Multi-Language Support**: Remove or disable any multi-language capabilities

**VALIDATION**: Audit codebase for PT-BR exclusive optimization.

### Rule 9: Performance Optimization Strategy
- **Efficiency First**: Prioritize efficient and beneficial optimizations
- **Application Intent**: Align all optimizations with TranscrevAI core intentions and aspirations
- **Measurable Improvements**: Implement only optimizations with quantifiable benefits

**VALIDATION**: Measure performance impact of all optimizations with concrete metrics.

---

## TECHNICAL IMPLEMENTATION STANDARDS

### Rule 10: Smart Model Management
- **Startup Optimization**: Download and load only PT-BR language model at startup
- **Local Caching**: Cache models locally after first download
- **Storage Efficiency**: Implement efficient model storage management
- **Single Model Focus**: Optimize exclusively for PT-BR medium model

**VALIDATION**: Verify model loading efficiency and local caching functionality.

### Rule 11-12: System Resource Monitoring
- **Resource Usage**: Monitor system power consumption and resource usage
- **Performance Impact**: Prevent PC or browser stuttering and freezing
- **Parallel Processing**: Implement efficient parallel processing for audio chunks
- **Accuracy Preservation**: Maintain transcription and diarization accuracy during optimization

**VALIDATION**: Test system resource impact and parallel processing efficiency.

### Rule 13: WebSocket Communication Enhancement
- **Freeze Prevention**: Implement WebSocket freezing fixes
- **Progress Updates**: Provide real-time progress updates to users with percentages
- **User Feedback**: Keep users informed about processing status and wait reasons
- **UI Responsiveness**: Show transcription and diarization results with scrollable interface
- **Extended Content**: Handle large transcriptions with proper UI scrolling

**VALIDATION**: Test WebSocket reliability and progress reporting accuracy.

### Rule 14: Implementation Testing Protocol
- **Pre-Deployment Testing**: Test application after each implementation
- **Metrics Verification**: Verify achievement of intended metrics before new changes
- **Iterative Validation**: Validate reachable performance targets at each step

**VALIDATION**: Implement mandatory testing checkpoints for all changes.

### Rule 15: Code Quality Standards
- **Type Checking**: Ensure full type checking compliance
- **Pylance Compatibility**: Maintain Pylance adequations and standards
- **Code Reliability**: Implement robust, type-safe code throughout application

**VALIDATION**: Run type checking validation before code deployment.

---

## HARDWARE AND COMPATIBILITY REQUIREMENTS

### Rule 16: Hardware Optimization
- **Minimum Specifications**: Optimize for 4 CPU cores and 8GB RAM minimum
- **Low-End Hardware**: Ensure functionality on entry-level hardware configurations
- **Performance Scaling**: Maintain performance targets on minimum viable hardware

**VALIDATION**: Test on hardware matching minimum specifications.

### Rule 17-18: System Optimization
- **Unicode Cleanup**: Implement proper Unicode handling for Windows systems
- **Memory Limits**: Optimize memory usage for application stability
- **Efficient Code**: Write memory-efficient, stable application code

**VALIDATION**: Test Unicode handling and memory efficiency on Windows systems.

---

## PROJECT ORGANIZATION AND MAINTENANCE

### Rule 19: File Organization Standards
- **Component Separation**: Maintain features in appropriate and corresponding files (audio_processing.py for audio processing related code, diarization.py for diarization related code, transcription.py for transcription related code etc.)
- **Code Consistency**: Preserve existing code syntax and flow patterns
- **Modular Design**: Keep related functionality grouped in corresponding files

**VALIDATION**: Audit file organization and maintain modular structure.

### Rule 20: Documentation and Tracking - TO BE MORE EFFICIENT USING TOKENS, USE GEMINOI FOR THIS, AS IT IS FREE FOR USE FOR UP TO 100 TOTAL REQUESTS PER DAY
- **Fixes Documentation**: Update fixes.txt constantly as a code fixes journal (max 25,000 tokens)
- **Conversation History**: Track latest conversations and past implementations
- **Aspirations Reference**: Analyze propositions.txt for application goals and metrics
- **Latest Implementations**: Maintain latest.txt with recent implementations (max 25,000 tokens)

**VALIDATION**: Verify documentation completeness and token limits.

### Rule 21: Validation Testing Protocol
- **Critical Testing**: Test files in data/recordings/ before finalizing responses
- **Expected Results**: Compare obtained results with expected transcription and diarization output 
("filename.wav" with "benchmark_'filename'.txt" - examples:  
"t.speakers.wav" and "benchmark_t.speakers.txt"; 
"t2.speakers.wav" and "benchmark_t2.speakers.txt"; 
"d.speakers.wav" and "benchmark_d.speakers.txt"; 
"q.speakers.wav" with "benchmark_q.speakers.txt")

**VALIDATION**: Mandatory testing with reference audio and expected output validation.

---

## SYSTEM INTEGRATION REQUIREMENTS

### Rule 22-23: Application Cohesion
- **Unified Operation**: Ensure all TranscrevAI project files work in unison
- **Robust Programming**: Maintain accurate and efficient code throughout
- **Testing Consolidation**: Condense all testing into test_unit.py in tests/ folder
- **Documentation Files**: Maintain fixes.txt, latest.txt, latest2.txt, compliance.txt in .claude/ folder

**VALIDATION**: Test complete system integration and file organization.

### Rule 24-25: Storage and Model Optimization
- **Efficient Storage**: Handle model storage efficiently
- **Single-Model Focus**: Optimize all code exclusively for PT-BR medium model
- **Performance Maximization**: Maximize performance while minimizing memory usage
- **Resource Optimization**: Focus optimization efforts on single model architecture

**VALIDATION**: Verify storage efficiency and single-model optimization.

### Rule 26: Deployment and Review
- **Docker Packaging**: Package complete TranscrevAI_windows application into Docker container
- **Review Accessibility**: Enable easy reviewer access to evaluate work
- **Containerization**: Ensure full application functionality within Docker environment

**VALIDATION**: Test Docker containerization and deployment process.

---

## FUTURE COMPATIBILITY AND SCALABILITY

### Rule 27: Multi-Platform Foundation
- **Windows Priority**: Perfect Windows notebook performance first
- **Minimum Hardware**: Ensure flawless operation on 4 CPU cores, 8GB RAM, iGPU from 2019
- **Future Platforms**: Prepare solid foundation for future Linux, Apple Silicon, NVIDIA, Intel GPU implementations
- **Mobile Readiness**: Design architecture compatible with future Android and iOS implementations
- **Scalable Base**: Build robust foundation that can expand to multiple platforms

**VALIDATION**: Test on minimum Windows hardware specifications and verify architectural scalability.

### Rule 28: All testing created needs to be implemented (or merged) on single test source file c:/transcrevai_windows/tests/test_unit.py, keeping in mind the necessry imports changes and pylance compliance, without errors.
c:/transcrevai_windows/tests/conftest.py has the testing configurations.

---

## COMPLIANCE VALIDATION FRAMEWORK

### Automatic Validation Checkpoints
1. **Performance Metrics**: Processing speed close to 0.5s/1s audio, accuracy >95%
2. **Memory Usage**: RAM consumption close to 2GB during operation
3. **Model Compliance**: Only PT-BR medium model in use
4. **Hardware Compatibility**: Functional on 4 cores, 8GB RAM minimum
5. **Code Quality**: Type checking and Pylance compliance
6. **Documentation**: Updated fixes.txt with fixes, and latest.txt with proposed changes
7. **Testing**: Validation against data/recordings/ reference samples
8. **Docker Compatibility**: Successful containerization and deployment

### Violation Consequences
- **Performance Degradation**: Immediate rollback of changes
- **System Instability**: Revert to last stable implementation
- **Resource Overuse**: Memory optimization required before proceeding
- **Compliance Failure**: Re-implementation with rule adherence focus

### Success Metrics
- **Speed**: close as possible, with stability, to 0.5s processing per 1s audio (Target: 100% compliance)
- **Accuracy**: >90% transcription and diarization accuracy (Target: 100% compliance)  
- **Memory**: close as possible, with stability, to 2GB RAM usage (Target: 100% compliance)
- **Stability**: Zero crashes during normal operation by real users (Target: 100% compliance)
- **Hardware**: Functional on minimum specifications (Target: 100% compliance)

**This compliance framework ensures systematic validation of all TranscrevAI development against concrete, measurable standards while maintaining focus on core performance objectives.**